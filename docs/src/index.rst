Welcome to ska-dlm-client's documentation!
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

The ska_dlm_client package provides clients for the `SKA Data Lifecycle Management system (DLM) <https://developer.skao.int/projects/ska-data-lifecycle/en/latest/overview/index.html>`_, enabling ingestion of data products and their metadata. There are two clients available, The Kafka client is being used in operations to ingest visibility data products created by the SDP receive pipeline, the Directory Watcher client is used in a more generic way to watch a configured directory and ingest new products as soon as they appear there. These two clients are based on the autogenerated openAPI DLM REST interface. Directly interfacing with the REST openAPI is not recommended, but it is described in the :doc:`openapi_readme` documentation for advanced use cases.


.. toctree::
   :maxdepth: 2
   :caption: Contents:

   api/index
   openapi_readme


Indices and tables
^^^^^^^^^^^^^^^^^^

* :ref:`genindex`
* :ref:`modindex`
* :ref:`search`


Sample Deployment
^^^^^^^^^^^^^^^^^
The clients are being deployed in a Kubernetes cluster, for example, to ingest data products from the SDP receive pipeline. A sample deployment is provided in the resources directory of the repository. For more information on how to deploy the clients in such an environment, view the `Sample Deployment <https://gitlab.com/ska-telescope/ska-dlm-client/-/blob/main/resources/sample-deployment.yaml>`_

However, the clients can also be used in a standalone environment, using a CLI interface, for example, to ingest data products from a local directory.

Standard Deployment
^^^^^^^^^^^^^^^^^^^

The standard deployment of the ska-dlm-client within the SKA Kubernetes environment uses a set of Helm charts and an associated configuration file.

Example Deployment
~~~~~~~~~~~~~~~~~~

An example deployment of the ska-dlm-client:

.. code-block:: shell

   helm install -f resources/dp-proj-user.yaml [-n <namespace>] ska-dlm-client charts/ska-dlm-client

This will deploy to the currently configured cluster and namespace.

.. note::

   More production-specific values (values files) will be added in a future release.

Values
~~~~~~

- ``global.dataProduct.pvc.name``: Name of the location of the data products or the directory to be watched.
- ``global.dataProduct.pvc.read_only``: Should be set to ``true`` for now. This limits the scope of what directory_watcher can do.
- ``setupStorageLocation``: Set to ``true`` if a test location/storage is needed.

**Note:** There is currently overlap between ``ska_dlm_client``, ``directory_watcher``, and ``kafka_watcher``. Values like ``storage_name`` and ``storage_root_directory`` appear in multiple sections because different components may reference different storage locations.

ska_dlm_client
~~~~~~~~~~~~~~

- ``image``: Container image to use for all watcher components (e.g., ``artefact.skao.int/ska-dlm-client``).
- ``version``: Image tag or version (e.g., ``"1.0.0"``).
- ``storage_name``: The DLM storage location name used during data registration.
- ``storage_root_directory``: Used as the root directory when generating URIs for DLM DB.
- ``securityContext``: Kubernetes context updated during deployment.
- ``ingest_server_url``: Full HTTP URL of the ingest server.
- ``storage_server_url``: Full HTTP URL of the storage server.
- ``request_server_url``: Full HTTP URL of the request server.

directory_watcher
~~~~~~~~~~~~~~~~~

- ``enabled``: Whether to deploy the ``directory-watcher`` component.
- ``directory_to_watch``: Filesystem path to monitor for new data products. Must exist within the mounted storage (e.g., ``/data/dlm/watch_dir``).
- ``storage_root_directory``: Root directory used to generate URIs for the DLM database. Should match ``ska_dlm_client.storage_root_directory``.
- ``skip_rclone_access_check_on_register``: If ``true``, skips verifying rclone access before attempting to register the file.
- ``register_contents_of_watch_directory``: If ``true``, registers all contents of the watch directory at startup, not just newly detected files.

kafka_watcher
~~~~~~~~~~~~~

- ``enabled``: Whether to deploy the ``kafka-watcher`` component.
- ``kafka_topic``: Kafka topic(s) to subscribe to for ingest event messages.
- ``storage_name``: The DLM storage location name to use when registering data items.
- ``check_rclone_access``: If ``true``, verifies rclone access before attempting registration. Optional.
- ``kafka_broker_url``: The Kafka bootstrap server to connect to. Required in production.

  - **In production:**
    - Keep ``kafka_server_local`` as ``false``
    - Provide the following explicitly:
      - ``kafka_broker_url`` as ``<service>.<namespace>:<port>`` (e.g., ``ska-sdp-kafka.dp-shared:9092``)
      - ``ska_dlm_client.ingest_server_url`` as ``http://<service>.<namespace>:<port>`` (e.g., ``http://ska-dlm-dev-ingest.dp-shared:80``)
  - **In local development:**
    - Set ``kafka_server_local: true``
    - Set ``ska_dlm_client.ingest_server_url`` to a local service (e.g., ``http://ska-dlm-dev-ingest:80``)
    - The Helm chart will automatically construct internal URLs using Kubernetes DNS:
      - Kafka broker URL: ``<service>.<namespace>:<port>``
      - Ingest URL: ``http://<service>.<namespace>:<port>``

ssh-storage-access Related Values
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

- ``ssh_storage_access``:
  - ``ssh_user_name``: Username to be used for remote SSH connections.
  - ``ssh_uid``: User ID for remote SSH connection.
  - ``ssh_gid``: Group ID for remote SSH connection.
  - ``xxx``: This needs to be one of ``daq``, ``pst`` or ``sdp``. All three can exist.
    - ``enabled``: Value is either ``true`` or ``false``.
    - ``deployment_name``: Name to be used for the Kubernetes deployment.
    - ``service_name``: Name to be used for the Kubernetes service.
    - ``pvc``:
      - ``name``: Name of the PVC to mount.
      - ``mount_path``: Path to mount PVC inside the pod.
      - ``read_only``: Should it be mounted read only.
    - ``secret``:
      - ``pub_name``: Name of the "ssh public key" Kubernetes secret.

startup-verification Related Values
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

- ``startup_verification``:
  - ``enabled``: Enable startup verification.
- ``kubectl``: Values related to the kubectl image used for k8s readiness testing.

Testing
^^^^^^^

A Helm chart has been created for testing: ``tests/charts/test-ska-dlm-client``.

The test chart is used to configure an existing DLM instance running in the same cluster namespace. Additional tests are planned (see ticket YAN-1910).

Usage:

.. code-block:: shell

   helm install -f resources/dp-proj-user.yaml test-ska-dlm-client tests/charts/test-ska-dlm-client/
   helm test test-ska-dlm-client
   helm uninstall test-ska-dlm-client

.. note::

   It is expected that the same values file can be used between this test and the ska-dlm-client.

Configuration
^^^^^^^^^^^^^

*Work in progress*

Use the ``src/ska_dlm_client/config.yaml`` file to specify the configuration of the ska-dlm-client. For example:

- The URLs of the DLM (Data Lifecycle Management) service and DPD (Data Product Dashboard) service.
- The Authentication Token used to access the DLM and DPD services.
- The name (and additional details) of the location and storage on which the ska-dlm-client will be run.

Here is an example of the config YAML (refer to the repository for the latest format):

.. code-block:: yaml

   auth_token: "Replace this with the authorization token"

   location:
     name: "MyLocationName"
     type: "MyLocationType"
     country: "MyLocationCountry"
     city: "MyLocationCity"
     facility: "MyLocationFacility"

   storage:
     name: "MyStorageName"
     type: "disk"
     interface: "posix"
     capacity: 100000000
     phase_level: "GAS"

   DLM:
     url: "http://dlm/api"

Startup Verification
^^^^^^^^^^^^^^^^^^^^

A ``startup verification`` can be enabled during the deployment of the watcher Helm chart. This will exercise the ``directory watcher`` by:

- Adding a data item to the watch directory.
- Giving the directory watcher a short amount of time to detect and register the data item.
- Querying the DLM request service for the data item name.
- Reporting a ``PASSED`` or ``FAILED`` response (based on the result) to the logs and exiting.

To check the logs of the startup verification pod:

.. code-block:: shell

   kubectl logs <ska dlm client startup-verification pod name>

Sample output:

.. code-block:: none

   2025-04-21 13:08:33,187 - INFO -

   PASSED startup tests

   2025-04-21 13:08:33,187 - INFO - Startup verification completed.
